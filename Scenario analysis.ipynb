{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (encode.py, line 804)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Anaconda3\\envs\\BN\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3331\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-3-8a63fd547b48>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import pysmile\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Anaconda3\\envs\\BN\\lib\\site-packages\\pysmile\\__init__.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from .encode import encode, SMILEEncodeError\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Anaconda3\\envs\\BN\\lib\\site-packages\\pysmile\\encode.py\"\u001b[1;36m, line \u001b[1;32m804\u001b[0m\n\u001b[1;33m    print repr(a)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pysmile\n",
    "\n",
    "## load license\n",
    "pysmile.License((\n",
    "    \"SMILE LICENSE cd06be93 97a7a599 29f4a47f \"\n",
    "    \"THIS IS AN ACADEMIC LICENSE AND CAN BE USED \"\n",
    "    \"SOLELY FOR ACADEMIC RESEARCH AND TEACHING, \"\n",
    "    \"AS DEFINED IN THE BAYESFUSION ACADEMIC \"\n",
    "    \"SOFTWARE LICENSING AGREEMENT. \"\n",
    "    \"Serial #: ckw9n4254hey3kiszvj6n5k0b \"\n",
    "    \"Issued for: Xiaoge Zhang (zxgcqupt@gmail.com) \"\n",
    "    \"Academic institution: Vanderbilt University \"\n",
    "    \"Valid until: 2020-03-22 \"\n",
    "    \"Issued by BayesFusion activation server\"\n",
    "    ),[\n",
    "    0xf5,0xdc,0x56,0x91,0x01,0x05,0xdb,0x8d,0xf0,0xbf,0x21,0xe9,0x58,0x09,0x41,0x79,\n",
    "    0x1f,0xd8,0xd4,0xb3,0x0a,0xaf,0x09,0xad,0xf2,0x41,0x58,0x93,0xc2,0x51,0x28,0xb0,\n",
    "    0x8d,0xad,0x69,0x38,0x8d,0x82,0x43,0x01,0xca,0xd9,0xd3,0xa2,0x5c,0x98,0xe2,0x9a,\n",
    "    0x99,0xbf,0xa4,0x17,0x4f,0xbb,0xd6,0x9a,0x72,0xf4,0x23,0xf5,0xed,0x94,0x4b,0x8e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BN:\n",
    "    def __init__(self):\n",
    "        print ('Loading the generated Bayesian network')\n",
    "\n",
    "    def get_node_id_by_name(self, name):\n",
    "        for handle in net.get_all_nodes():\n",
    "            if net.get_node_id(handle) == name:\n",
    "                return handle\n",
    "    \n",
    "    def print_posterior_probs(self, node_id):\n",
    "        posteriors = net.get_node_value(node_id) ## marginal distribution\n",
    "        nodeName= net.get_node_name(node_id)\n",
    "\n",
    "        for i in range(0, len(posteriors)):\n",
    "            print(\"P(\" + nodeName + \"=\" + net.get_outcome_id(node_id, i) + \")=\" + str(posteriors[i]))\n",
    "            \n",
    "    def print_consequence_prob(self, node_id):\n",
    "        childNodes = net.get_children(node_id)\n",
    "        for child in childNodes:\n",
    "            posteriors = net.get_node_value(child)\n",
    "            node_id = net.get_node_id(child)\n",
    "            \n",
    "            for i in range(0, len(posteriors)):\n",
    "                if net.get_outcome_id(node_id, i) == 'Yes':\n",
    "                    print(\"P(\" + node_id + \"=\" + net.get_outcome_id(node_id, i) + \")=\" + str(posteriors[i]))\n",
    "     \n",
    "    def get_node_definition(self, node_id):\n",
    "        return net.get_node_definition(node_id)\n",
    "        \n",
    "    def change_evidence_and_update(self, node_id):\n",
    "        print (\"Before observing \" + str(net.get_node_name(node_id)) + \"----------->\")\n",
    "        self.print_posterior_probs(node_id)\n",
    "        \n",
    "        print (\"\\n\")\n",
    "        print (\"----- Consequence\")\n",
    "        self.print_consequence_prob(node_id)\n",
    "        net.set_evidence(node_id, 0)\n",
    "        net.update_beliefs()\n",
    "        \n",
    "        print ('\\n')\n",
    "        print (\"After observing \" + str(net.get_node_name(node_id)) + \"----------->\")\n",
    "        self.print_posterior_probs(node_id)\n",
    "        \n",
    "        print (\"\\n\")\n",
    "        print (\"----- Consequence\")\n",
    "        self.print_consequence_prob(node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = pysmile.Network()\n",
    "net.set_bayesian_algorithm(3)\n",
    "net.read_file(\"NTSB.xdsl\")\n",
    "net.update_beliefs()\n",
    "\n",
    "network = BN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation -- Part I\n",
    "\n",
    "##### Change prior probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcome(nodeID):\n",
    "    childNodes = net.get_children(nodeID)\n",
    "\n",
    "    for child in childNodes:\n",
    "        posteriors = net.get_node_value(child)\n",
    "        node_id = net.get_node_id(child)\n",
    "\n",
    "        for i in range(0, len(posteriors)):\n",
    "            if net.get_outcome_id(node_id, i) == 'Yes':\n",
    "                print(\"P(\" + node_id + \"=\" + net.get_outcome_id(nodeID, i) + \")=\" + str(posteriors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landinggearNodeID = network.get_node_id_by_name(\"Landinggearmaingearstrut\")\n",
    "\n",
    "Yes = net.get_node_definition(landinggearNodeID)[0]\n",
    "originalProb = Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listProb = [Yes, 10*Yes, 100*Yes, 10000*Yes, 1000000*Yes, 0.1, 0.2, 0.3, 0.5, 0.8, 0.9, 1]\n",
    "\n",
    "for p in listProb:\n",
    "    print (\"The occurrence probability of landing gear main gear strut is \", p)\n",
    "    \n",
    "    nodeDef = [p,  1-p]\n",
    "    \n",
    "    net.set_node_definition(landinggearNodeID, nodeDef)\n",
    "    net.update_beliefs()\n",
    "    \n",
    "    get_outcome(landinggearNodeID)\n",
    "    \n",
    "    print (\"\\n\")\n",
    "    \n",
    "\n",
    "nodeDef = [originalProb, 1 - originalProb]\n",
    "net.set_node_definition(landinggearNodeID, nodeDef)\n",
    "net.update_beliefs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation -- Part II\n",
    "#### Observe more and more evidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Observe landing gear main gear strut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeName = \"Landinggearmaingearstrut\"\n",
    "nodeID = network.get_node_id_by_name(nodeName)\n",
    "\n",
    "network.change_evidence_and_update(nodeID)\n",
    "\n",
    "consequenceList = [\"Destroyedaircraftdamage\", \"Minoraircraftdamage\", \"Minorinjury\"]\n",
    "consequence = []\n",
    "\n",
    "print (\"\\n\")\n",
    "for item in consequenceList:\n",
    "    NodeID = network.get_node_id_by_name(item)\n",
    "    res = net.get_node_value(NodeID)\n",
    "    print (\"Yes and No probs of \" + item + \" \" + str(res))\n",
    "    \n",
    "    consequence.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Observe landing gear emergency extension assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeName = \"Landinggearemergencyextensionassembly\"\n",
    "nodeID = network.get_node_id_by_name(nodeName)\n",
    "network.change_evidence_and_update(nodeID)\n",
    "\n",
    "print (\"\\n\")\n",
    "for item in consequenceList:\n",
    "    NodeID = network.get_node_id_by_name(item)\n",
    "    \n",
    "    res = net.get_node_value(NodeID)\n",
    "    print (\"Yes and No probs of \" + item + \" \" + str(res))\n",
    "    \n",
    "    consequence.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Observe landing gear  locking mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeName = \"Landinggeargearlockingmechanism\"\n",
    "nodeID = network.get_node_id_by_name(nodeName)\n",
    "network.change_evidence_and_update(nodeID)\n",
    "\n",
    "print (\"\\n\")\n",
    "for item in consequenceList:\n",
    "    NodeID = network.get_node_id_by_name(item)\n",
    "    \n",
    "    res = net.get_node_value(NodeID)\n",
    "    print (\"Yes and No probs of \" + item + \" \" + str(res))\n",
    "    \n",
    "    consequence.append(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Observe landing gear main gear attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeName = \"Landinggearmaingearattachment\"\n",
    "nodeID = network.get_node_id_by_name(nodeName)\n",
    "network.change_evidence_and_update(nodeID)\n",
    "\n",
    "print (\"\\n\")\n",
    "for item in consequenceList:\n",
    "    NodeID = network.get_node_id_by_name(item)\n",
    "        \n",
    "    res = net.get_node_value(NodeID)\n",
    "    print (\"Yes and No probs of \" + item + \" \" + str(res))\n",
    "    \n",
    "    consequence.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "consequence = np.array(consequence)\n",
    "\n",
    "df = pd.DataFrame([['Landing gear \\n main gear strut failure', 'Destroyed aircraft damage', consequence[0, 0]],\n",
    "                   ['Landing gear \\n emergency extension assembly failure', 'Destroyed aircraft damage', consequence[3, 0]],\n",
    "                   ['Landing gear \\n locking mechanism failure', 'Destroyed aircraft damage', consequence[6, 0]],\n",
    "                   ['Landing gear \\n main gear attachment failure', 'Destroyed aircraft damage', consequence[9, 0]],\n",
    "                   ['Landing gear \\n main gear strut failure', 'Minor aircraft damage', consequence[1, 0]],\n",
    "                   ['Landing gear \\n emergency extension assembly failure', 'Minor aircraft damage', consequence[4, 0]],\n",
    "                   ['Landing gear \\n locking mechanism failure', 'Minor aircraft damage', consequence[7, 0]],\n",
    "                   ['Landing gear \\n main gear attachment failure', 'Minor aircraft damage', consequence[10, 0]],\n",
    "                   ['Landing gear \\n main gear strut failure', 'Minor personnel injury', consequence[2, 0]],\n",
    "                   ['Landing gear \\n emergency extension assembly failure', 'Minor personnel injury', consequence[5, 0]],\n",
    "                   ['Landing gear \\n locking mechanism failure', 'Minor personnel injury', consequence[8, 0]],\n",
    "                   ['Landing gear \\n main gear attachment failure', 'Minor personnel injury', consequence[11, 0]]], \n",
    "                  columns=['stage','Outcome','val'])\n",
    "\n",
    "df_pivot = df.pivot(\"stage\", \"Outcome\", \"val\").reset_index()\n",
    "\n",
    "order = ['Landing gear \\n main gear strut failure', 'Landing gear \\n emergency extension assembly failure', \n",
    "         'Landing gear \\n locking mechanism failure', 'Landing gear \\n main gear attachment failure']\n",
    "\n",
    "mapping = {day: i for i, day in enumerate(order)}\n",
    "key = df_pivot['stage'].map(mapping)    \n",
    "df_pivot = df_pivot.iloc[key.argsort()]\n",
    "\n",
    "params = {'legend.fontsize': 20, 'legend.handlelength': 2}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# Draw the bar chart\n",
    "ax = df_pivot.plot(kind='bar', x='stage', figsize=(18, 11))\n",
    "ax.set_xlabel(\"Observed evidence\", fontsize = 24, fontweight = 'bold')\n",
    "ax.set_ylabel(\"Probability\", fontsize = 24, fontweight = 'bold')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tick_params(axis='x', labelsize=17)\n",
    "plt.tick_params(axis='y', labelsize=17)\n",
    "plt.tight_layout()\n",
    "plt.savefig('evidence.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in net.get_all_nodes():\n",
    "    parent_ids = net.get_parent_ids(i)\n",
    "    \n",
    "    child_ids = net.get_child_ids(i)\n",
    "    #print (parent_ids)\n",
    "    if len(parent_ids) == 0 and len(child_ids) >= 2:\n",
    "        print (net.get_node_name(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
